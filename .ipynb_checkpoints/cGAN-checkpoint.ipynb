{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2915,
     "status": "ok",
     "timestamp": 1631870709804,
     "user": {
      "displayName": "Marvin Schmitt",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08441018833103684368"
     },
     "user_tz": -120
    },
    "id": "eJ-ZjGNQyFn3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend, optimizers, Model, applications, metrics, activations, losses\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, LeakyReLU, Dropout, Flatten, Dense, Reshape, Concatenate, Conv2DTranspose, ReLU, Activation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger, TensorBoard\n",
    "import tensorflow.keras.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23915,
     "status": "ok",
     "timestamp": 1631870733717,
     "user": {
      "displayName": "Marvin Schmitt",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08441018833103684368"
     },
     "user_tz": -120
    },
    "id": "GgJLetdbgEup",
    "outputId": "115a7a01-3f2e-4503-9fda-2a20948182fb"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-827c829e2526>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/content/gdrive\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "from google.colab import files \n",
    "\n",
    "\n",
    "drive.mount(\"/content/gdrive\")\n",
    "print(os.getcwd())\n",
    "os.chdir(\"/content/gdrive/My Drive/AML2021/AML2021\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 643,
     "status": "ok",
     "timestamp": 1631870734354,
     "user": {
      "displayName": "Marvin Schmitt",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08441018833103684368"
     },
     "user_tz": -120
    },
    "id": "Uk2ZiTgXwII7"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 2000\n",
    "INITIAL_EPOCH = 0\n",
    "BATCH_SIZE = 16\n",
    "INPUT_SHAPE = (299,299,3)\n",
    "CLASSES = 2\n",
    "LATENT_DIMS = 100\n",
    "OPT_GEN = optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "OPT_DISC = optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "os.makedirs('models/GAN', exist_ok = True) \n",
    "os.makedirs('models/GAN/imgs', exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gyDRpkK7mlK"
   },
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1631870734753,
     "user": {
      "displayName": "Marvin Schmitt",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08441018833103684368"
     },
     "user_tz": -120
    },
    "id": "vfFPTDiIx3QT",
    "outputId": "6409209d-17cf-448f-b158-5f1410712129"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 299, 299, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 299, 299, 32) 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 299, 299, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 299, 299, 32) 0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 150, 150, 64) 18496       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 150, 150, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 150, 150, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 150, 150, 64) 0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 150, 150, 64) 36928       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 150, 150, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 150, 150, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 150, 150, 64) 0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 75, 75, 128)  73856       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 75, 75, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 75, 75, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 75, 75, 128)  0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 75, 75, 128)  147584      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 75, 75, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 75, 75, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 75, 75, 128)  0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 38, 38, 256)  295168      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 38, 38, 256)  1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 38, 38, 256)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 38, 38, 256)  0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 38, 38, 256)  590080      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 38, 38, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 38, 38, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 38, 38, 256)  0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 19, 19, 512)  1180160     dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 19, 19, 512)  2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 19, 19, 512)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 19, 19, 512)  0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 184832)       0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            184833      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            369666      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,903,427\n",
      "Trainable params: 2,900,547\n",
      "Non-trainable params: 2,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def block(i, filter, kernel, stride):\n",
    "  x = Conv2D(filter, kernel, strides=stride, padding='same')(i)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = LeakyReLU(alpha=0.2)(x)\n",
    "  x = Dropout(0.5)(x)\n",
    "  return x\n",
    "\n",
    "i = Input(shape=INPUT_SHAPE)\n",
    "x = block(i, 32, (3,3), (1,1))\n",
    "x = block(x, 64, (3,3), (2,2))\n",
    "x = block(x, 64, (3,3), (1,1))\n",
    "x = block(x, 128, (3,3), (2,2))\n",
    "x = block(x, 128, (3,3), (1,1))\n",
    "x = block(x, 256, (3,3), (2,2))\n",
    "x = block(x, 256, (3,3), (1,1))\n",
    "x = block(x, 512, (3,3), (2,2))\n",
    "x = Flatten()(x)\n",
    "real_fake_out = Dense(1, activation=\"sigmoid\")(x)\n",
    "class_out = Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "discriminator = Model(i,[real_fake_out, class_out], name=\"discriminator\")\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 789,
     "status": "ok",
     "timestamp": 1631870738943,
     "user": {
      "displayName": "Marvin Schmitt",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08441018833103684368"
     },
     "user_tz": -120
    },
    "id": "Yuy44J3T6ec6",
    "outputId": "313871ed-be8e-4b84-8247-50040c30ba4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.49945325]], shape=(1, 1), dtype=float32) tf.Tensor([[0.5001768  0.49982324]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "y, r = discriminator(np.random.rand(1,299,299,3).astype(\"float32\"))\n",
    "print(y,r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0afpDpW7s4S"
   },
   "source": [
    "#Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 331,
     "status": "ok",
     "timestamp": 1631870739272,
     "user": {
      "displayName": "Marvin Schmitt",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08441018833103684368"
     },
     "user_tz": -120
    },
    "id": "Dxk12xaS7sOn",
    "outputId": "52459ac6-5183-404e-e7d6-fdc6c390c02c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 82944)        8377344     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 81)           243         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 9, 9, 1024)   0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 9, 9, 1)      0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 9, 9, 1025)   0           reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 18, 18, 512)  13120512    concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 18, 18, 512)  2048        conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 18, 18, 512)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 36, 36, 256)  3277056     re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 36, 36, 256)  1024        conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 36, 36, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 74, 74, 128)  524416      re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 74, 74, 128)  512         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 74, 74, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 148, 148, 64) 204864      re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 148, 148, 64) 256         conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 148, 148, 64) 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 299, 299, 3)  4803        re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid (TFOpLambda)    (None, 299, 299, 3)  0           conv2d_transpose_4[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 25,513,078\n",
      "Trainable params: 25,511,158\n",
      "Non-trainable params: 1,920\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# original paper has pading=same and filtersize=5, we adept this a bit to match the requiered outputsize of 299,299\n",
    "def block(i, filter, kernel, strides=(2,2), padding='same'):\n",
    "  x = Conv2DTranspose(filter, kernel, strides=strides, padding=padding)(i)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = ReLU()(x)\n",
    "  return x\n",
    "\n",
    "z = Input(shape=(LATENT_DIMS,))\n",
    "zx = Dense(9*9*1024)(z)\n",
    "zx = Reshape((9,9,1024))(zx)\n",
    "c = Input(shape=(CLASSES,))\n",
    "cx = Dense(9*9*1)(c)\n",
    "cx = Reshape((9,9,1))(cx)\n",
    "x = Concatenate(axis=-1)([zx,cx])\n",
    "x = block(x, 512, (5,5), strides=(2,2), padding='same')#18x18x512\n",
    "x = block(x, 256, (5,5), strides=(2,2), padding='same')#36x36x256\n",
    "x = block(x, 128, (4,4), strides=(2,2), padding='valid')#74x74x128\n",
    "x = block(x, 64, (5,5), strides=(2,2), padding='same')#148x148x64\n",
    "x = Conv2DTranspose(3, (5,5), strides=(2,2), padding='valid')(x)#299x299x64\n",
    "o = activations.sigmoid(x)# original paper has tanh, but since we normalize between 0,1 instead of -1,1 we use sigmoid\n",
    "\n",
    "generator = Model([z,c],o)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 344,
     "status": "ok",
     "timestamp": 1631870740133,
     "user": {
      "displayName": "Marvin Schmitt",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08441018833103684368"
     },
     "user_tz": -120
    },
    "id": "_1w4xq8i_r5b",
    "outputId": "f2884272-6e1f-4827-a910-f3a3554a619b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 299, 299, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator([np.random.rand(1,100).astype(\"float32\"), np.random.rand(1,2).astype(\"float32\")]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-R5Hgyx-egyg"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 93960,
     "status": "ok",
     "timestamp": 1631870835186,
     "user": {
      "displayName": "Marvin Schmitt",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08441018833103684368"
     },
     "user_tz": -120
    },
    "id": "DrrUXe5wfTss",
    "outputId": "b3427f5c-2a3c-48c3-de42-e3539af352a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16324, 299, 299, 3) (16324, 2)\n",
      "0 255\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "x_train = np.load(\"x_train.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_train.min(), x_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "executionInfo": {
     "elapsed": 12091,
     "status": "error",
     "timestamp": 1631871251656,
     "user": {
      "displayName": "Marvin Schmitt",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "08441018833103684368"
     },
     "user_tz": -120
    },
    "id": "vjc11CSbediV",
    "outputId": "e9dce854-a7d9-411c-ebca-de792e734357"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch 0/2000, batch 361/1021"
     ]
    }
   ],
   "source": [
    "previous_disc_loss = float('inf')\n",
    "previous_gen_loss = float('inf')\n",
    "\n",
    "for epoch in range(INITIAL_EPOCH, EPOCHS):\n",
    "  num_batches = int(np.ceil(x_train.shape[0]/BATCH_SIZE))\n",
    "  gen_losses = []\n",
    "  disc_losses = []\n",
    "  # batching\n",
    "  for batch in range(int(num_batches)):\n",
    "    indices = np.arange(x_train.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    batch_start = batch*BATCH_SIZE\n",
    "    batch_end = batch_start+BATCH_SIZE\n",
    "    batch_idx = indices[batch_start:batch_end]\n",
    "\n",
    "    # training\n",
    "    random_latent_vectors = tf.random.normal(shape=(BATCH_SIZE, LATENT_DIMS))\n",
    "    condition = tf.one_hot(\n",
    "        tf.random.uniform(shape=(BATCH_SIZE, ), minval=0, maxval=2, dtype=tf.int32),\n",
    "        depth=2, dtype=tf.int32)\n",
    "    real = tf.cast(utils.normalize(x_train[batch_idx], axis=0), tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      fake = generator([random_latent_vectors, condition])\n",
    "\n",
    "      discrimination_real, y_real = discriminator(real)\n",
    "      discrimination_fake, y_fake = discriminator(fake)\n",
    "\n",
    "      binary_cross_entropy = losses.BinaryCrossentropy()\n",
    "      categorical_cross_entropy = losses.CategoricalCrossentropy()\n",
    "      loss_disc_real = binary_cross_entropy(tf.ones_like(discrimination_real), discrimination_real)\n",
    "      loss_disc_fake = binary_cross_entropy(tf.zeros_like(discrimination_fake), discrimination_fake)\n",
    "      loss_cls_real = categorical_cross_entropy(y_train[batch_idx], y_real)\n",
    "      loss_cls_fake = categorical_cross_entropy(condition, y_fake)\n",
    "      loss_disc = loss_disc_real + loss_disc_fake + loss_cls_real + loss_cls_fake\n",
    "\n",
    "      loss_gen_disc = binary_cross_entropy(tf.ones_like(discrimination_fake), discrimination_fake)\n",
    "      loss_gen_cls = categorical_cross_entropy(condition, y_fake)\n",
    "      loss_gen = loss_gen_disc + loss_gen_cls\n",
    "    \n",
    "    grads_disc = disc_tape.gradient(loss_disc, discriminator.trainable_weights)\n",
    "    OPT_DISC.apply_gradients(zip(grads_disc, discriminator.trainable_weights))\n",
    "\n",
    "    grads_gen = gen_tape.gradient(loss_gen, generator.trainable_weights)\n",
    "    OPT_GEN.apply_gradients(zip(grads_gen, generator.trainable_weights))\n",
    "\n",
    "    # reporting\n",
    "    gen_losses.append(loss_gen.numpy())\n",
    "    disc_losses.append(loss_disc.numpy())\n",
    "\n",
    "    if batch == 0:\n",
    "        z = tf.random.normal(shape=(2, LATENT_DIMS))\n",
    "        c = tf.one_hot([0, 1], depth=2, dtype=tf.int32)\n",
    "\n",
    "        imgs = generator([z, c])\n",
    "        img_0 = tf.keras.preprocessing.image.array_to_img(imgs[0])\n",
    "        img_1 = tf.keras.preprocessing.image.array_to_img(imgs[1])\n",
    "\n",
    "        img_0.save(f\"models/GAN/imgs/generated_image_c0_ep{epoch:04}.png\")\n",
    "        img_1.save(f\"models/GAN/imgs/generated_image_c1_ep{epoch:04}.png\")\n",
    "        \n",
    "    print(f\"\\r epoch {epoch}/{EPOCHS}, batch {batch+1}/{num_batches}\", end=\"\")\n",
    "  \n",
    "  avg_disc_loss = sum(disc_losses) / len(disc_losses)\n",
    "  avg_gen_loss = sum(gen_losses) / len(gen_losses)\n",
    "  print(f\", disc loss= {avg_disc_loss}, gen loss= {avg_gen_loss}\")\n",
    "  with open(\"models/GAN/log.csv\",\"a+\") as f:\n",
    "    f.write(f\"{epoch}, {avg_gen_loss}, {avg_disc_loss}\")\n",
    "\n",
    "  # saving\n",
    "  if avg_disc_loss < previous_disc_loss:\n",
    "    discriminator.save('models/GAN/best-Discriminator.hdf5')\n",
    "    print(f\"disc loss improved from {previous_disc_loss} to {avg_disc_loss}, best-Discriminator.hdf5 saved\")\n",
    "  if avg_gen_loss < previous_gen_loss:\n",
    "    generator.save('models/GAN/best-Generator.hdf5')\n",
    "    print(f\"gen loss improved from {previous_gen_loss} to {avg_gen_loss}, best-Generator.hdf5 saved\")\n",
    "  previous_disc_loss = avg_disc_loss\n",
    "  previous_gen_loss = avg_gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "cGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
